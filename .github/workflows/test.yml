name: Test Pipeline

on:
  push:
    branches: [ main, develop, "feature/*", "bug/*", "hotfix/*" ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:
    inputs:
      debug:
        description: 'Enable debug mode'
        required: false
        default: 'false'
        type: boolean
      test_level:
        description: 'Test level to run'
        required: false
        default: 'full'
        type: choice
        options:
        - 'quick'
        - 'full'
        - 'security-only'

# Security settings
permissions:
  contents: read
  security-events: write
  actions: read
  checks: write
  pull-requests: write

# Global environment variables
env:
  TERM: xterm-256color
  FORCE_COLOR: 1
  DEBIAN_FRONTEND: noninteractive

jobs:
  # Fast preliminary checks
  pre-flight:
    name: Pre-flight Checks
    runs-on: ubuntu-latest
    timeout-minutes: 5
    outputs:
      should-run-tests: ${{ steps.changes.outputs.should-run }}
      test-level: ${{ steps.test-config.outputs.level }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Check for relevant changes
        id: changes
        run: |
          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            echo "should-run=true" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Check if any relevant files changed
          if git diff --name-only HEAD~1 HEAD | grep -E '\.(sh|bats|yml|yaml|md)$|^wizard\.sh$|^tests/|^\.github/'; then
            echo "should-run=true" >> $GITHUB_OUTPUT
          else
            echo "should-run=false" >> $GITHUB_OUTPUT
            echo "No relevant files changed, skipping tests"
          fi

      - name: Configure test level
        id: test-config
        run: |
          if [[ "${{ github.event.inputs.test_level }}" ]]; then
            echo "level=${{ github.event.inputs.test_level }}" >> $GITHUB_OUTPUT
          elif [[ "${{ github.event_name }}" == "pull_request" ]]; then
            echo "level=full" >> $GITHUB_OUTPUT
          elif [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            echo "level=full" >> $GITHUB_OUTPUT
          else
            echo "level=quick" >> $GITHUB_OUTPUT
          fi

  # Lint and static analysis
  lint:
    name: Lint & Static Analysis
    runs-on: ubuntu-latest
    needs: pre-flight
    if: needs.pre-flight.outputs.should-run-tests == 'true'
    timeout-minutes: 10
    strategy:
      matrix:
        tool: [shellcheck, bashate, security-scan]
      fail-fast: false

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Cache lint tools
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/shellcheck
            ~/.local/bin
          key: lint-tools-${{ runner.os }}-${{ hashFiles('.github/workflows/test.yml') }}

      - name: Install lint tools
        run: |
          # Install shellcheck
          sudo apt-get update && sudo apt-get install -y shellcheck

          # Install bashate
          pip3 install --user bashate

          # Install security tools
          pip3 install --user bandit safety

          # Add to PATH
          echo "$HOME/.local/bin" >> $GITHUB_PATH

      - name: Run ShellCheck
        if: matrix.tool == 'shellcheck'
        run: |
          echo "Running ShellCheck on all shell scripts..."

          # Create results directory
          mkdir -p test-results/shellcheck

          # Find and check all shell scripts
          find . -name "*.sh" -not -path "./.git/*" -not -path "./node_modules/*" | while read -r script; do
            echo "Checking: $script"
            if ! shellcheck -f gcc "$script" >> test-results/shellcheck/results.txt 2>&1; then
              echo "ShellCheck failed for: $script" >&2
            fi
          done

          # Check if there were any failures
          if [[ -s test-results/shellcheck/results.txt ]]; then
            echo "ShellCheck found issues:"
            cat test-results/shellcheck/results.txt
            exit 1
          else
            echo "ShellCheck passed for all scripts"
          fi

      - name: Run Bashate
        if: matrix.tool == 'bashate'
        run: |
          echo "Running Bashate on all shell scripts..."

          mkdir -p test-results/bashate

          # Run bashate with reasonable rules
          find . -name "*.sh" -not -path "./.git/*" -not -path "./node_modules/*" \
            -exec bashate -i E006,E042 {} + > test-results/bashate/results.txt 2>&1 || {
            echo "Bashate found issues:"
            cat test-results/bashate/results.txt
            exit 1
          }

          echo "Bashate passed for all scripts"

      - name: Security scan
        if: matrix.tool == 'security-scan'
        run: |
          echo "Running security analysis..."

          mkdir -p test-results/security

          # Custom security checks for shell scripts
          ./tests/security/check-shell-security.sh > test-results/security/shell-security.txt 2>&1 || true

          # Check for common security issues
          echo "Checking for hardcoded secrets..."
          if grep -r -E "(password|secret|key|token).*=" --include="*.sh" . | grep -v "test" | grep -v "example"; then
            echo "WARNING: Potential hardcoded secrets found"
            # Don't fail on warnings, just report
          fi

          echo "Security scan completed"

      - name: Upload lint results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: lint-results-${{ matrix.tool }}
          path: test-results/
          retention-days: 7

  # Main test matrix
  test:
    name: Tests
    runs-on: ${{ matrix.os }}
    needs: [pre-flight, lint]
    if: needs.pre-flight.outputs.should-run-tests == 'true'
    timeout-minutes: 30
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest]
        shell: [bash]
        test-suite: [unit, integration, security]
        include:
          # Add specific combinations for comprehensive testing
          - os: ubuntu-20.04
            shell: bash
            test-suite: compatibility
          - os: ubuntu-latest
            shell: bash
            test-suite: performance
        exclude:
          # Skip some combinations for quick tests
          - os: macos-latest
            test-suite: performance
      fail-fast: false

    env:
      TEST_OS: ${{ matrix.os }}
      TEST_SUITE: ${{ matrix.test-suite }}
      LIVING_DOCS_ROOT: ${{ github.workspace }}
      DEBUG: ${{ github.event.inputs.debug == 'true' && '1' || '0' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for git-based tests

      - name: Setup test environment
        run: |
          # Set up common test environment
          echo "Setting up test environment for ${{ matrix.os }}"

          # Create test directories
          mkdir -p test-results/${{ matrix.test-suite }}
          mkdir -p test-artifacts

          # Set up git for tests
          git config --global user.email "test@example.com"
          git config --global user.name "Test User"
          git config --global init.defaultBranch main

      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/bats
            ~/.local/bin
            /tmp/living-docs-test-cache
          key: test-deps-${{ matrix.os }}-${{ hashFiles('tests/**/*.bats', 'tests/**/*.sh') }}
          restore-keys: |
            test-deps-${{ matrix.os }}-

      - name: Install Bats
        run: |
          if [[ "${{ matrix.os }}" == "ubuntu"* ]]; then
            # Install Bats on Ubuntu
            sudo apt-get update
            sudo apt-get install -y bats git

            # Install bats-support and bats-assert
            git clone https://github.com/bats-core/bats-support.git /tmp/bats-support
            git clone https://github.com/bats-core/bats-assert.git /tmp/bats-assert

            sudo mkdir -p /usr/local/lib/bats
            sudo cp -r /tmp/bats-support /usr/local/lib/bats/
            sudo cp -r /tmp/bats-assert /usr/local/lib/bats/

          elif [[ "${{ matrix.os }}" == "macos"* ]]; then
            # Install Bats on macOS
            brew install bats-core

            # Install bats helpers
            brew install bats-support bats-assert
          fi

          # Verify installation
          bats --version

      - name: Install additional test dependencies
        run: |
          if [[ "${{ matrix.os }}" == "ubuntu"* ]]; then
            sudo apt-get install -y jq curl wget gpg diffutils findutils coreutils
          elif [[ "${{ matrix.os }}" == "macos"* ]]; then
            brew install jq curl wget gnupg gnu-sed findutils coreutils
            # Add GNU tools to PATH for consistency
            echo "/opt/homebrew/opt/gnu-sed/libexec/gnubin" >> $GITHUB_PATH
            echo "/opt/homebrew/opt/findutils/libexec/gnubin" >> $GITHUB_PATH
            echo "/opt/homebrew/opt/coreutils/libexec/gnubin" >> $GITHUB_PATH
          fi

      - name: Run unit tests
        if: matrix.test-suite == 'unit'
        run: |
          echo "Running unit tests..."

          # Run Bats unit tests
          if [[ -d tests/bats ]]; then
            bats --recursive --formatter junit --output test-results/unit tests/bats/ || exit_code=$?

            # Also run with tap output for debugging
            bats --recursive --tap tests/bats/ > test-results/unit/tap-output.txt

            exit ${exit_code:-0}
          else
            echo "No unit tests found"
          fi

      - name: Run integration tests
        if: matrix.test-suite == 'integration'
        run: |
          echo "Running integration tests..."

          # Set up integration test environment
          export TEST_TEMP_DIR="/tmp/living-docs-integration-test"
          mkdir -p "$TEST_TEMP_DIR"

          # Run integration tests
          if [[ -d tests/integration ]]; then
            for test_script in tests/integration/test_*.sh; do
              if [[ -f "$test_script" ]]; then
                echo "Running: $test_script"
                bash "$test_script" 2>&1 | tee "test-results/integration/$(basename "$test_script").log"
                test_exit_code=${PIPESTATUS[0]}

                if [[ $test_exit_code -ne 0 ]]; then
                  echo "Integration test failed: $test_script"
                  exit $test_exit_code
                fi
              fi
            done
          else
            echo "No integration tests found"
          fi

      - name: Run security tests
        if: matrix.test-suite == 'security'
        run: |
          echo "Running security tests..."

          # Create security test results directory
          mkdir -p test-results/security

          # Run security-specific tests
          if [[ -f tests/security/test_security.bats ]]; then
            bats --formatter junit --output test-results/security tests/security/test_security.bats
          fi

          # Run custom security checks
          if [[ -f tests/security/check-shell-security.sh ]]; then
            bash tests/security/check-shell-security.sh > test-results/security/security-check.log 2>&1
          fi

          # Test wizard.sh security
          echo "Testing wizard.sh security..."
          bash tests/security/test-wizard-security.sh > test-results/security/wizard-security.log 2>&1 || true

      - name: Run compatibility tests
        if: matrix.test-suite == 'compatibility'
        run: |
          echo "Running compatibility tests on ${{ matrix.os }}..."

          # Test different shell versions if available
          for shell in bash dash; do
            if command -v "$shell" >/dev/null 2>&1; then
              echo "Testing with $shell..."
              "$shell" --version

              # Run basic wizard functionality test
              echo "Testing wizard.sh with $shell..."
              "$shell" -n wizard.sh  # Syntax check
            fi
          done

          # Test with different sed versions (important for macOS/Linux compatibility)
          ./tests/compatibility/test-sed-compatibility.sh > test-results/compatibility/sed-test.log 2>&1 || true

      - name: Run performance tests
        if: matrix.test-suite == 'performance'
        run: |
          echo "Running performance tests..."

          mkdir -p test-results/performance

          # Test wizard.sh performance with large projects
          if [[ -f tests/performance/test-large-project.sh ]]; then
            bash tests/performance/test-large-project.sh > test-results/performance/large-project.log 2>&1
          fi

          # Test drift detection performance
          if [[ -f tests/performance/test-drift-performance.sh ]]; then
            bash tests/performance/test-drift-performance.sh > test-results/performance/drift-performance.log 2>&1
          fi

      - name: Collect test artifacts
        if: always()
        run: |
          # Collect logs and artifacts
          echo "Collecting test artifacts..."

          # Copy any generated logs
          find . -name "*.log" -not -path "./.git/*" -exec cp {} test-artifacts/ \; 2>/dev/null || true

          # Copy test outputs
          find test-results/ -type f -exec cp {} test-artifacts/ \; 2>/dev/null || true

          # Generate summary
          echo "Test Summary for ${{ matrix.os }} - ${{ matrix.test-suite }}" > test-artifacts/summary.txt
          echo "Timestamp: $(date)" >> test-artifacts/summary.txt
          echo "OS: ${{ matrix.os }}" >> test-artifacts/summary.txt
          echo "Test Suite: ${{ matrix.test-suite }}" >> test-artifacts/summary.txt

          # List artifacts
          echo "Generated artifacts:" >> test-artifacts/summary.txt
          ls -la test-artifacts/ >> test-artifacts/summary.txt

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-${{ matrix.os }}-${{ matrix.test-suite }}
          path: |
            test-results/
            test-artifacts/
          retention-days: 7

      - name: Upload test reports
        uses: dorny/test-reporter@v1
        if: always() && matrix.test-suite == 'unit'
        with:
          name: Test Results (${{ matrix.os }})
          path: test-results/unit/*.xml
          reporter: java-junit
          fail-on-error: false

  # Security-focused job
  security-audit:
    name: Security Audit
    runs-on: ubuntu-latest
    needs: pre-flight
    if: needs.pre-flight.outputs.should-run-tests == 'true'
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Cache security tools
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/trivy
            ~/.local/bin
          key: security-tools-${{ runner.os }}-v1

      - name: Install security tools
        run: |
          # Install Trivy for vulnerability scanning
          sudo apt-get update
          sudo apt-get install wget apt-transport-https gnupg lsb-release
          wget -qO - https://aquasecurity.github.io/trivy-repo/deb/public.key | sudo apt-key add -
          echo "deb https://aquasecurity.github.io/trivy-repo/deb $(lsb_release -sc) main" | sudo tee -a /etc/apt/sources.list.d/trivy.list
          sudo apt-get update
          sudo apt-get install trivy

      - name: Run filesystem security scan
        run: |
          echo "Running filesystem security scan..."
          trivy fs --format json --output security-results.json .
          trivy fs --format table .

      - name: Check for secrets
        uses: gitleaks/gitleaks-action@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITLEAKS_LICENSE: ${{ secrets.GITLEAKS_LICENSE }}

      - name: Custom security checks
        run: |
          echo "Running custom security checks..."

          mkdir -p security-artifacts

          # Check for insecure patterns in shell scripts
          echo "Checking for insecure shell patterns..."
          grep -r -n "eval\|exec\|system\|bash -c\|sh -c" --include="*.sh" . > security-artifacts/insecure-patterns.txt || echo "No insecure patterns found"

          # Check for hardcoded paths that might be security issues
          echo "Checking for hardcoded sensitive paths..."
          grep -r -n "/tmp\|/var/tmp\|\.\./" --include="*.sh" . > security-artifacts/path-issues.txt || echo "No path issues found"

          # Check permissions on scripts
          echo "Checking script permissions..."
          find . -name "*.sh" -exec ls -la {} \; > security-artifacts/script-permissions.txt

      - name: Upload security results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-audit-results
          path: |
            security-results.json
            security-artifacts/
          retention-days: 30

  # Generate comprehensive test report
  test-report:
    name: Generate Test Report
    runs-on: ubuntu-latest
    needs: [test, security-audit, lint]
    if: always() && needs.pre-flight.outputs.should-run-tests == 'true'
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: all-artifacts

      - name: Generate comprehensive report
        run: |
          echo "Generating comprehensive test report..."

          mkdir -p final-report

          # Create main report
          cat > final-report/test-report.md << 'EOF'
          # Living Docs Test Report

          **Generated:** $(date)
          **Commit:** ${{ github.sha }}
          **Branch:** ${{ github.ref_name }}
          **Trigger:** ${{ github.event_name }}

          ## Summary

          EOF

          # Add test results summary
          echo "## Test Results by OS and Suite" >> final-report/test-report.md
          echo "" >> final-report/test-report.md

          for artifact_dir in all-artifacts/test-results-*; do
            if [[ -d "$artifact_dir" ]]; then
              artifact_name=$(basename "$artifact_dir")
              echo "### $artifact_name" >> final-report/test-report.md

              # Check for test result files
              if [[ -f "$artifact_dir/summary.txt" ]]; then
                echo '```' >> final-report/test-report.md
                cat "$artifact_dir/summary.txt" >> final-report/test-report.md
                echo '```' >> final-report/test-report.md
              fi
              echo "" >> final-report/test-report.md
            fi
          done

          # Add security results
          echo "## Security Audit Results" >> final-report/test-report.md
          echo "" >> final-report/test-report.md

          if [[ -d "all-artifacts/security-audit-results" ]]; then
            echo "Security scan completed. Check artifacts for detailed results." >> final-report/test-report.md
          else
            echo "Security scan was not run or failed." >> final-report/test-report.md
          fi

          # Add lint results
          echo "## Lint Results" >> final-report/test-report.md
          echo "" >> final-report/test-report.md

          for lint_artifact in all-artifacts/lint-results-*; do
            if [[ -d "$lint_artifact" ]]; then
              tool_name=$(basename "$lint_artifact" | sed 's/lint-results-//')
              echo "### $tool_name" >> final-report/test-report.md
              echo "Lint check completed." >> final-report/test-report.md
              echo "" >> final-report/test-report.md
            fi
          done

          echo "Test report generated successfully"

      - name: Upload final report
        uses: actions/upload-artifact@v4
        with:
          name: comprehensive-test-report
          path: final-report/
          retention-days: 30

      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            if (fs.existsSync('final-report/test-report.md')) {
              const report = fs.readFileSync('final-report/test-report.md', 'utf8');
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: report
              });
            }

  # Final status check
  test-status:
    name: Test Status
    runs-on: ubuntu-latest
    needs: [test, security-audit, lint, test-report]
    if: always() && needs.pre-flight.outputs.should-run-tests == 'true'
    timeout-minutes: 5

    steps:
      - name: Check test results
        run: |
          echo "Checking overall test status..."

          # Check if critical jobs passed
          if [[ "${{ needs.test.result }}" == "failure" ]]; then
            echo "❌ Tests failed"
            exit 1
          elif [[ "${{ needs.security-audit.result }}" == "failure" ]]; then
            echo "❌ Security audit failed"
            exit 1
          elif [[ "${{ needs.lint.result }}" == "failure" ]]; then
            echo "❌ Lint checks failed"
            exit 1
          else
            echo "✅ All checks passed"
          fi

      - name: Set status
        run: |
          if [[ "${{ needs.test.result }}" == "success" && "${{ needs.security-audit.result }}" == "success" && "${{ needs.lint.result }}" == "success" ]]; then
            echo "status=success" >> $GITHUB_ENV
          else
            echo "status=failure" >> $GITHUB_ENV
          fi